{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSA8001- Programming Task 1  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written answer provide your solution in Markdown in the cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to print your output. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "\n",
    "- In `application_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day (0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there now in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 438445 rows in df_application\n",
      "There are 1047185 rows in df_credit\n",
      "There are 438398 unique bank clients in df_application\n",
      "There are 45924 unique bank clients in df_credit\n",
      "There are 776325 rows in df\n",
      "There are 36396 unique clients in df\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "import os\n",
    "os.chdir('C:/Users/khuon/OneDrive/Documents/4. Macquarie/2. Session 2/4. BUSA8001 Applied Predictive Analytics/Assignment 1/Assignment1-S2-2024/data')\n",
    "import pandas as pd\n",
    "df_application = pd.read_csv('application_record.csv',header=0)\n",
    "df_credit = pd.read_csv('credit_record.csv',header=0)\n",
    "\n",
    "# 2.\n",
    "num_of_rows_application = len(df_application)\n",
    "num_of_rows_credit = len(df_credit)\n",
    "print(f'There are {num_of_rows_application} rows in df_application')\n",
    "print(f'There are {num_of_rows_credit} rows in df_credit') \n",
    "\n",
    "# 3.\n",
    "uniq_application = df_application['ID'].nunique(dropna=False)\n",
    "print(f'There are {uniq_application} unique bank clients in df_application')\n",
    "uniq_credit = df_credit['ID'].nunique(dropna=False)\n",
    "print(f'There are {uniq_credit} unique bank clients in df_credit')\n",
    " \n",
    "# 4.\n",
    "df = pd.merge(df_application,df_credit,how=\"inner\")\n",
    "\n",
    "#5\n",
    "num_of_rows_df = len(df)\n",
    "print(f'There are {num_of_rows_df} rows in df')\n",
    "uniq_df = df['ID'].nunique(dropna=False)\n",
    "print(f'There are {uniq_df} unique clients in df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. There are 438,445 rows in df_application and there are 1,047,185 rows in df_credit\n",
    "\n",
    "3. There are 438,398 unique bank clients in df_application and there are 45,924 unique bank clients in df_credit\n",
    "\n",
    "6. Df is the combination of the 2 data frame: df_credit and df_application. One ID under df_application datadframe can have many MONTHS_BALANCE and STATUS value from ID under df_credit, therefore one ID under df can appear many times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "\n",
    "2. Create a new *numpy* array called `list_of_past_due` that includes the unique ID numbers of clients whose `STATUS = 1` at any point during the last 12 months (hint: count the current month as the first month). (2 marks) \n",
    "\n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` is in `list_of_past_due`, keeping only one row for each `ID` (hint: keep the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "\n",
    "5. Increase `df_final` to a total of 4,500 rows by adding rows from `df` with unique `ID`s which are not in `list_of_past_due`. To do this start adding the rows from the beginning of `df`. (hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "\n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. (1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1737 rows in df_final\n"
     ]
    }
   ],
   "source": [
    "#1. \n",
    "STATUS_mapping = {'C':0,'X':0,'0':0, '1':1,'2':1,'3':1,'4':1,'5':1}\n",
    "df['STATUS'] = df['STATUS'].replace(STATUS_mapping)\n",
    "df['STATUS'] = df['STATUS'].astype(int)\n",
    "\n",
    "#2\n",
    "import numpy as np\n",
    "num_list_of_past_due = df['ID'][(df['STATUS']==1) & (df['MONTHS_BALANCE']>-12)]\n",
    "list_of_past_due = np.array(num_list_of_past_due)\n",
    "\n",
    "#3\n",
    "df_final = df[df['ID'].isin(list_of_past_due)].drop_duplicates(subset='ID', keep='first')\n",
    "num_of_rows_df_final = len(df_final)\n",
    "print(f'There are {num_of_rows_df_final} rows in df_final')\n",
    "\n",
    "#4\n",
    "df_final['y']=1\n",
    "\n",
    "#5\n",
    "needed_rows = 4500-len(df_final)\n",
    "list_of_non_past_due = df[~df['ID'].isin(list_of_past_due)]['ID'].unique()\n",
    "df_non_past_due = df[df['ID'].isin(list_of_non_past_due)].drop_duplicates(subset='ID', keep='first')\n",
    "added_rows= df_non_past_due.head(needed_rows)\n",
    "df_final = pd.concat([df_final,added_rows])\n",
    " \n",
    "#6\n",
    "df_final['y']=df_final['y'].fillna(0)\n",
    "df_final.drop(['STATUS','MONTHS_BALANCE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,737 rows in df_final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "1. Delete `ID` column from `df_final` and reset its index. (1 marks)\n",
    "2. Assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable in `df_final`, which variables are numeric and which ones are nominal? Answer this question by copying and completing the following table (6 marks)\n",
    "\n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|||\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|||\n",
    "\n",
    "3. Using appropriate functions find and comment on the missing values in `df_final` (3 marks)   \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_EDUCATION_TYPE    1831\n",
       "OCCUPATION_TYPE        1354\n",
       "CNT_CHILDREN             74\n",
       "CODE_GENDER               0\n",
       "DAYS_EMPLOYED             0\n",
       "CNT_FAM_MEMBERS           0\n",
       "FLAG_EMAIL                0\n",
       "FLAG_PHONE                0\n",
       "FLAG_WORK_PHONE           0\n",
       "FLAG_MOBIL                0\n",
       "DAYS_BIRTH                0\n",
       "FLAG_OWN_CAR              0\n",
       "NAME_HOUSING_TYPE         0\n",
       "NAME_FAMILY_STATUS        0\n",
       "NAME_INCOME_TYPE          0\n",
       "AMT_INCOME                0\n",
       "FLAG_OWN_REALTY           0\n",
       "y                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 \n",
    "df_final.drop(['ID'], axis=1, inplace=True)\n",
    "df_final.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#3\n",
    "df_final.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n",
    "\n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|5|CNT_CHILDREN, AMT_INCOME, DAYS_BIRTH, DAYS_EMPLOYED, CNT_FAM_MEMBERS|\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|12|CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE,FLAG_MOBIL, FLAG_WORK_PHONE, FLAG_PHONE, FLAG_EMAIL, y|\n",
    "\n",
    "The variable that has the highest number of missing values is NAME_EDUCATION_TYPE with 1,831 missing values, second highest is OCCUPATION_TYPE with 1,354 missing values and third is CNT_CHILDREN with 74 missing values. Other variables do not miss any values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "1. Use an appropriate `pandas` function to impute missing values in `df_final` (15 marks)\n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0], inplace=True)\n",
    "\n",
    "df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0], inplace=True)\n",
    "\n",
    "df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_EDUCATION_TYPE_mapping = {'Lower secondary':1,'Secondary / secondary special':2,'Incomplete higher':3,'Higher education':4}\n",
    "df_final['NAME_EDUCATION_TYPE']=df_final['NAME_EDUCATION_TYPE'].replace(NAME_EDUCATION_TYPE_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_CODE_GENDER = pd.get_dummies(df_final[['CODE_GENDER']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_CODE_GENDER)\n",
    "df_final = df_final.drop('CODE_GENDER',axis=1)\n",
    "\n",
    "one_hot_FLAG_OWN_CAR = pd.get_dummies(df_final[['FLAG_OWN_CAR']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_FLAG_OWN_CAR)\n",
    "df_final = df_final.drop('FLAG_OWN_CAR',axis=1)\n",
    "\n",
    "one_hot_FLAG_OWN_REALTY= pd.get_dummies(df_final[['FLAG_OWN_REALTY']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_FLAG_OWN_REALTY)\n",
    "df_final = df_final.drop('FLAG_OWN_REALTY',axis=1)\n",
    "\n",
    "one_hot_NAME_INCOME_TYPE= pd.get_dummies(df_final[['NAME_INCOME_TYPE']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_NAME_INCOME_TYPE)\n",
    "df_final = df_final.drop('NAME_INCOME_TYPE',axis=1)\n",
    "\n",
    "one_hot_NAME_FAMILY_STATUS= pd.get_dummies(df_final[['NAME_FAMILY_STATUS']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_NAME_FAMILY_STATUS)\n",
    "df_final = df_final.drop('NAME_FAMILY_STATUS',axis=1)\n",
    "\n",
    "one_hot_NAME_HOUSING_TYPE= pd.get_dummies(df_final[['NAME_HOUSING_TYPE']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_NAME_HOUSING_TYPE)\n",
    "df_final = df_final.drop('NAME_HOUSING_TYPE',axis=1)\n",
    "\n",
    "one_hot_OCCUPATION_TYPE= pd.get_dummies(df_final[['OCCUPATION_TYPE']], dtype = int, drop_first = True)\n",
    "df_final = df_final.join(one_hot_OCCUPATION_TYPE)\n",
    "df_final = df_final.drop('OCCUPATION_TYPE',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "1. Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "2. Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1\n",
    "y = np.array(df_final['y'], dtype=int)\n",
    "\n",
    "#2\n",
    "X = df_final.drop('y',axis=1)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "1. Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 75% train and 25% test datasets (2.5 marks) \n",
    "    - Set random_state to 8 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "2. Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8, stratify=y)\n",
    "\n",
    "#2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Logistic Regression and Random Forest Classifiers and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "1. Train a Logistic Regression Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies   \n",
    "2. Train a Random Forest Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "\n",
    "When printing accuracies round the values to three decimal places.      \n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training Dataset: Logistic Regresssion = 0.660\n",
      "Accuracy Test Dataset - Logistic Regresssion = 0.660\n",
      "Accuracy Training Dataset: Random Forest = 0.977\n",
      "Accuracy Test Dataset: Random Forest = 0.887\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=10)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_accuracy_train = lr.score(X_train_scaled, y_train)\n",
    "lr_accuracy_test = lr.score(X_test_scaled, y_test)\n",
    "print(f'Accuracy Training Dataset: Logistic Regresssion = {lr_accuracy_train:.3f}')\n",
    "print(f'Accuracy Test Dataset - Logistic Regresssion = {lr_accuracy_test:.3f}')\n",
    "\n",
    "#2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=10)\n",
    "forest.fit(X_train, y_train) \n",
    "x_pred_test = forest.predict(X_test)\n",
    "x_pred_train = forest.predict(X_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy Training Dataset: Random Forest = {accuracy_score(y_train, x_pred_train):.3f}')\n",
    "print(f'Accuracy Test Dataset: Random Forest = {accuracy_score(y_test, x_pred_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**. \n",
    "\n",
    "a) Comment and compare the training and test accuracies for each classifier computed in Question 9. What can we say about the extent of overfitting for each classifier? (5 marks)   \n",
    "b) Comment and compare the accuracies across the two classifiers. Which classifier provides better forecasts? (5 marks)   \n",
    "c) What can you say about the presence of nonlinearities in the dataset? (10 marks)   \n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Accuracy score of Training dataset and Test dataset for Logistic Regression Classifier is close to each other at 0.66 and 0.66 respectively. On the other hand, accuracy score on Training dataset is significantly higher than accuracy score for Test dataset for Random Forest Classifier at 0.977 and 0.877 respectively. This indicates overfitting for Random Forest Classifier, which is when model performs better on Training dataset than Test dataset, perhaps because the model fits too closely to the training dataset, or has too many parameters. \n",
    "\n",
    "b) Despite overfitting, Random Forest Classifier outperformed Logistic Regression Classifer both on Training and Test dataset. Therefore the Random Forest Classifier should be preferred over Logistic Regression Classifier as it makes better forecasts.\n",
    "\n",
    "c) Logistic Regression Classifier assumes linear relationship between the independent and dependent variables and is limited to modeling linear relationship between variables. On the other hand, Random Forest can handle non-linear relationship and can model complex relationship between variables, both linearity and non-linearities in the model. As Random Classifier outperforms Logistic Regression Classifier on both Training and Test dataset, therefore nonlinearities are present in both dataset and the reason why Random Forest outperforms Logistic Regression Classifier is because Random Forest Classifier capture the non-linearity relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
